{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b895d6",
   "metadata": {},
   "source": [
    "<img src=\"http://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"center\" border=\"0\"><br>\n",
    "\n",
    "\n",
    "### <font color= dodgerblue>ML & DL based Investment Strategies for BTC using Technical Trading Indicators and On-Chain Data Analysis</font>\n",
    "\n",
    "#### Author: \n",
    "J Francisco Salazar G\n",
    "#### Date: \n",
    "February 2022\n",
    "\n",
    "#### Director: \n",
    "Yves Hilpisch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3bca97",
   "metadata": {},
   "source": [
    "**Abstract**\n",
    "\n",
    "<font color= gray>The core topic of the paper is concerned with the prediction of short-term market direction movement for bitcoin spot price exploring traditional statistics, machine learning and deep learning methods applied to time series data. We consider this a critical step as it forms the core of an algorithmic trading strategy that could be then deployed in real-time on the cloud. Here, the basic idea for modeling future market direction of a single asset, is based on predicting bitcoin's sign of future returns and transforming a sequence; in this case, time series-data, into a matrix structure where we have features and labels. We select the 25 most important features with `SelectKBest` as we include technical analysis indicators and on-chain data metrics as features to the mix for our supervised learning algorithms. We let them \"learn\" about the relationships between features and labels data from a simple classification problem approach. Finally, based on the premise \"that a process of directional price changes is predictable if the accuracy of the predictions is significantly higher than 50%\", we train and back-test a strategy in bitcoin based on our algorithms for directional (long/short) trading and compare the different models strategies perfomances' numerically and visually.</font>\n",
    "\n",
    "**Key words:** <font color= gray> Machine Learning \\& Deep Learning Algorithms – Asset Movement Prediction – Digital Assets – Bitcoin – On-Chain Analysis – Prediction-based Trading </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d495646",
   "metadata": {},
   "source": [
    "## <font color= dodgerblue> Introduction </font>\n",
    "Since the apocalyptic pandemic event [<sup>1</sup>](#fn1 \"The pandemic triggered the _Great Liquidity Crisis_, the largest volatility-adjusted re-pricing of markets in 30+ years, accompanied by the most aggressive market support operations conducted in central bank modern history. The impact of the COVID-19 crisis was felt worldwide taking a hefty toll on human lives and economic activity due to global lock-downs that were implemented to contain its spread. Fear and uncertainty translated into sharp and rapid declines of traditional financial assets and newly adopted asset classes globally, such as bitcoin.\") that shook the world in march 2020, bitcoin's store of value potential as [digital gold](https://blog.chainalysis.com/reports/bitcoin-market-data-exchanges-trading), built on the foundation of transparent finance and “the hedge it offers against the existing monetary world order\" [1] have particularly made it attractive as an investment. In fact, the year 2021 has seen the emergence of cryptocurrencies as an institutional asset class. In October 2020, interest and appetite for digital assets from institutional investors such as family offices, hedge funds and asset managers like insurance companies grew exponentially. Moreover, the corporate sponsorship of bitcoin by the likes of Microstrategy, Square, PayPal and Tesla further boosted institutional investors' appetite for bitcoin and other cryptocurrencies. Many holders are now using cryptocurrencies for their intended purpose; which is payments, as around [USD 12 billion are transferred across several blockchains daily](https://www.visualcapitalist.com/visualizing-the-rise-of-cryptocurrency-transactions/).\n",
    "\n",
    "\n",
    "Product of the Information Age; the Internet birthed Bitcoin during the Global Financial Crisis in 2009, which fundamentally shifted how a financial system distributes trust by eliminating the roles of several institutions that rely on centralized authorities and creating an ecosystem based on computer science and cryptography. Bitcoin’s creator, Satoshi Nakamoto, originally described the need for an electronic payment system based on cryptographic proof [2]. Bitcoin challenge to the current financial infrastructure is forcing all market participants to closely monitor and understand this new market. We refer to bitcoin as an investable new asset class called digital asset characterized by extreme volatility, that is part of a stimulus-fueled mania and has somehow called into question the very basis of economic organization.\n",
    "As how to appropriately value digital assets; in particular bitcoin, is a very complex, challenging and controversial aspect of the cryptomarket, we will briefly deep dive into a state-of-the-art framework out there to evaluate bitcoin value. There are several forecasting models and theories about the drivers of cryptoasset valuations [3] but they have produced minimum accuracy in predicting bitcoin’s future price.\n",
    "  \n",
    "\n",
    "Our project is ordered as follows. In section I, we briefly introduce blockchain, digital assets, Bitcoin/bitcoin and provide some insight into bitcoin's microstructure risks. In Section II; we motivate this work and based on the literature reviewed, we present a predictive framework upon the combination of engineered-data, novel metrics and features involved when attacking academically the binary classification problem of predicting bitcoin's movement. Section III covers the data used, the building and training of our supervised learning algorithms for bitcoin's (BTC) price movement prediction problem. In Section IV, we present the results and open a discussion on the performance of our models to the tasks assigned as well as observations and difficulties encountered while tackling each task and problems that arise in practice when using predictions to algorithmically trade financial instruments. Section V presents concluding remarks and opens the discussion about lines of research to explore on topics not covered in-depth during the present project.\n",
    "\n",
    "# <font color= dodgerblue> SECTION I: UNDERSTANDING BLOCKCHAIN,  DIGITAL ASSETS AND BITCOIN </font>\n",
    "\n",
    "## <font color= dodgerblue> Evolution and Adoption of Blockchain and Digital Assets </font>\n",
    "As new technologies disrupt several industries, evidence of increasing mainstream adoption of blockchain technology and the modernization of payments have translated into the rise of digital money. Blockchain is the core technology underlying Bitcoin, but  experts  see  the  potential  for  it  uses cases to span over several industries [4] as it has the capability to transform how businesses and governments operate in a variety of aspects. This technology by itself has great potential to simplify and speed up transactions and information transfer in a new ecosystem that is constantly evolving.\n",
    "\n",
    "#### <font color= dodgerblue>  The Blockchain Technology behind Bitcoin: A Novel Mix of Existing Technologies </font>\n",
    "\n",
    "The  major  innovation  of  blockchain  Bitcoin  was  to  combine  the  use  of  three  long-standing existing technologies:\n",
    "\n",
    "- peer-to-peer (P2P) network,\n",
    "- cryptography,\n",
    "- network servicing consensus protocol.\n",
    "\n",
    "Blockchain is an emerging technology that forms the underlying infrastructure behind cryptocurrencies such as bitcoin; and  was  originally developed as a way to record transactions in a transparent, secure, immutable and efficient way. The term ‘blockchain’ (a series of blocks that form a chain) refers to a specific way of structuring data on a distributed ledger technology (DLT) platform [5]. It is a public ledger  technology  that  helps  carry  out  transactions  without  the  centralized  oversight  of a third party organization, which translates into less friction and low cost/transaction fees to a process; thus enabling the sharing and updating of records in a distributed and decentralised way. \n",
    "\n",
    "In a blockchain network there is no centralized database as all the participating nodes (users/machines) store a copy of the data which means that there is no central point of failure in the network. Since the data is stored by all nodes, it can sustain the loss of a few nodes in the network as other nodes pick it up [6]. But it also means that rather than a  single  centralized  server or database, the blockchain captures an entire decentralized network of machines, with each one acting as a node within that specific network. This ultimately serves to reduce the need for central authorities to clear transactions and certify ownership. It is indeed a departure from the centralized system that we are used to currently where a particular entity is in charge of authentication.\n",
    "\n",
    "The key proposition of the blockchain is that each “block” represents a unique set of transactional data that has been validated under a particular blockchain’s defined protocol. Every time a transaction is validated in accordance with the consensus mechanism, the distributed ledger is synchronized to every participant in the network, linking together a peer-to-peer network. Decentralized transactions making use of decentralized ledger technologies or blockchain technologies are settled among several servers and can be limited to a trusted few (“permissioned” networks), or open to the public (“permissionless”). \n",
    "\n",
    "Bitcoin specifically uses a consensus mechanism known as ‘proof of work’ which is highly energy and cost intensive. Network protection through Proof-of-Work (PoW) forms the heart of Bitcoin and many other blockchain platforms in terms of authentication of a transaction. Regardless of the types of consensus mechanisms, their basic job is to ensure the protection of the network and prevent double spend attack. Satoshi was able to solve the double-spend issue via the introduction of a timestamp into the consensus algorithm; which is a cryptographic function used to secure a network. In the case of Bitcoin, this algorithm is known as SHA-256 (64-digit hexadecimal hash). But the major disadvantage of the PoW consensus is the amount of time it takes to solve this deterministic* algorithm, lower limits on the number of transactions in a block and the cost of electricity involved in successfully mining the block. This led to many blockchain platforms developing alternate consensus algorithms, of which the most notable is the Proof-of-Stake (PoS). PoS is another primary protocol used to validate transactions on the blockchain for cryptocurrencies. Owners of proof-of-stake tokens can act as cryptocurrency validators themselves or outsource to staking intermediaries, putting a portion of their token holdings “at stake” in order to earn a position to validate the blockchain. As compensation, those selected to validate the blockchain earn cryptocurrency rewards that can be interpreted as investment income, [generating a yield for token holders](https://www.scribd.com/document/516548432/JPM-Crypto-Market-210701). In ohter words, \"yield farming\" allows stakers to earn returns on their crypto holdings in terms of annual percentage yields (APY).   \n",
    "\n",
    "### <font color= dodgerblue> What is Digital Money? </font>\n",
    "Before diving deeper into the world of digital assets, we find useful for understanding digital money to review a conceptual framework (mapping) to categorize new digital monies, proposed by the IMF (Figure 1). It lays out a taxonomy - the “money tree” featuring the different models of digital money and present a framework focused on four attributes of means of payment: type, value, backstops, and technology ([IMF Fintech Notes](https://www.imf.org/en/Publications/fintech-notes/Issues/2019/07/12/The-Rise-of-Digital-Money-47097)). These attributes helps us distinguish among five different means of payment: (1) central bank money (cash, notes and coins); (2) cryptocurrency; (3) b-money, which currently is issued by banks typically covers commercial bank deposits; (4) electronic money, or e-money, offered by new private sector providers; and (5) i-money, short for investment money, issued by private investment funds. It  shows  for  the  purpose  of  our  paper, that bitcoin is a cryptocurrency considered an object-based mean of payment with its own unit of account, minted by non-banks and issued on a blockchain, of the permissionless type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b4bfc5",
   "metadata": {},
   "source": [
    "**Figure 1: The rise of digital money**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url = \"Digital Assets Map.PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bbef56",
   "metadata": {},
   "source": [
    "### <font color= dodgerblue>  What are digital assets? </font>\n",
    "\n",
    "The alternative investments universe which consists of hedge funds, real estate, **digital assets**, private debt and private equity has doubled since 2014 reaching $25tr in 2021. \n",
    "The demand for alternatives in the post pandemic period reflects investors' desire for:\n",
    "- higher yields/returns relative to traditional asset classes, \n",
    "- diversification away from traditional assets classes\n",
    "- hedging against potentially adverse inflation outcomes given the current amount of stimulus\n",
    "\n",
    "\n",
    "When the term “digital asset” was coined in the mid-90s, it referred to items like images, videos, audio, and documentation. The market for digital assets has evolved dramatically from Bitcoin’s origins as a peer-to-peer system of value transfer to the development of smart contracts and countless other blockchain applications, to the point that some argue cryptography-based digital assets have become a disruptive revolutionary technology when compared to the  advent of the Internet.\n",
    "\n",
    "\n",
    "It is important to note that in the past several years and in the absence of regulation, private firms and entrepreneurs started distributing new instruments called “digital assets,” “cryptocurrencies”, and “cryptoassets” using the terms interchangeably since there is not a sole widely agreed-upon regulatory framework nor a taxonomy for the categories included in digital assets, yet [7]. \n",
    "\n",
    "Existing digital asset frameworks tend to focus primarily on the asset form and the underlying technology. Largely inspired by digital tokens issued on public and permissionless networks, existing frameworks tend to assume the use of DLT and cryptography are the dominant criteria (“digital  token  issued  on  a  DLT  system”). This  ignores  the  fact  that  there  are  various alternative  mechanisms  and  technologies  to  represent  assets  in  digital  form  that  do  not  involve DLT based concepts. \n",
    "\n",
    "For the purpose of our paper, cryptocurrency is a subcategory under the umbrella of digital assets in its broader sense.\n",
    "\n",
    "### <font color= dodgerblue> What is Bitcoin? </font>\n",
    "\n",
    "Bitcoin is a free and open source software code that is nested on the Internet. The Bitcoin network is a complete financial system that facilitates the transfer and custody of bitcoin, a new digital asset. Lowercase ‘b’ bitcoin, the asset, is a standardized unit of value embedded in the  network.  It  is  part  of  a  new  class  of  asset  that  derives  its  value  from  the  information  being verified and the size and growth of the network. Essentially, a larger network of users and miners makes the underlying blockchain more secure, and implies greater acceptability of the cryptocurrency on that blockchain.\n",
    "\n",
    "To summarize:\n",
    "- It is a digital asset - a new asset class - and has potential for widespread social adoption\n",
    "- It is scarce, divisible, portable, transferable, secure, and fungible.\n",
    "- A convenient store of value and an alternative payment system.\n",
    "- Some argue that the sharp increase in the value of this cryptocurrency indicates that—despite strong fluctuations many market participants trust in its store-of-value function.\n",
    "- Bitcoin is the first verifiable digital asset that already is scarce as considering its asset facet, from a liquidity perspective, the total supply of bitcoin is set to be 21mn globally, while approximately 18.6 mn bitcoins have been mined.\n",
    "- Bitcoin has a simple accounting system in contrast to traditional account-based accounting systems: Bitcoin’s [UTXO-based accounting system](https://academy.glassnode.com/concepts/utxo) makes tracking supply and auditing monetary policy simple.\n",
    "- Bitcoin has emerged as an alternative to gold, while ethereum and other crytpocurrencies have turned out as application currencies providing investors with exposure to the advancement of blockchain technology.\n",
    "- At this stage of development, it is more probable than not that regulators will come up with regulation related to risks arising from bitcoin as a legal tender, the new payments ecosystem and trading in bitcoin (which are topics we are of the opinion should be addressed).\n",
    "\n",
    "\n",
    "The foundation for cryptocurrencies, notably [bitcoin](https://www.thebword.org/c/the-b-word), is that there is no centralized monetary authority, relying instead on a blockchain or a distributed public ledger that is open and shared by  a  network  of  connected  computers  that  are  incentivized  to  validate  and  record  transactions.  The  public  ledger  is  a  running  list  of  completed  transactions, timestamped and recorded in blocks, making it transparent for anyone on the network to check the validity of past transactions.\n",
    "\n",
    "The recent rise of the [Lightning Network](https://charts.woobull.com/bitcoin-lightning-network/), the launch of BITO (ProShares Bitcoin Strategy) the first bitcoin ETF in the US, a recent soft-fork change to Bitcoin called [Taproot](https://cointelegraph.com/news/bitcoin-taproot-upgrade-improves-the-network-as-btc-price-impact-may-be-limited), a 2nd layer payments solutions helped by [El Salvador's adoption](https://www.imf.org/en/News/Articles/2021/11/22/mcs-el-salvador-staff-concluding-statement-of-the-2021-article-iv-mission) of bitcoin as legal tender  and more recently, the [first sovereign bitcoin bond](https://www.ft.com/content/18b59559-378b-4f14-ab2e-b54ede79816c) are the most recent eye catching developments for this asset class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c9b5a",
   "metadata": {},
   "source": [
    "### <font color= dodgerblue> Risks inherent in bitcoin markets microstructure </font>\n",
    "\n",
    "This  new  asset  class  has  very  novel  and  interesting  properties embedded into its market microstructure. Cryptocurrencies can be traded 24/7 and 365 days per year,  either ‘off-chain’ on  hundreds of different centralized exchanges or transferred  directly ‘on-chain’ using smart contracts on the Ethereum chain or other public blockchains via P2P trading venues called decentralized exchanges [8]. However, are there vulnerabilities in the miscrostructure of bitcoin that are different from other classes?\n",
    "\n",
    "The microstructure of bitcoin markets is vulnerable in a very particular and a very specific way. The key for bitcoin specifically is to understand that vulnerability to a potential volatility shock is more acute in the context of idiosyncratic risks to the asset class. In this case, the reliance on US dollar based stablecoins; specifically Tether, which represents more than half of global trading volume in bitcoin **constitutes a potential risk**. Serving as the equivalent of “cash” or “lubricant” in the digital asset space, most bitcoin trading occurs relative to stablecoins; particularly USDT which is issued by [Tether Ltd.](https://tether.to/), and was the  [subject  of scrutiny](https://www.bloomberg.com/news/articles/2021-10-15/tether-bitfinex-to-pay-fines-totaling-42-5-million-cftc-says) because of the opaqueness in  the  composition  of  its reserve  assets,  and  its underlying  profile  risk.  \n",
    "\n",
    "The  tail  risk  to  bitcoin markets therefore  is  a  sudden  loss  of  confidence  in  USDT,  which  would  likely  generate  a  severe  liquidity shock, jeopardizing access to the largest pools of demand and liquidity in both spot and derivatives. However these concerns about the long-term [stability of USDT](https://www.cnbc.com/2018/02/02/tether-what-you-need-to-know-about-the-cryptocurrency-worrying-markets.html) have been around for several years. Here a  recent podcast by [Bloomberg](https://www.bloomberg.com/news/audio/2021-10-07/big-take-stablecoin-tether-grows-to-69-billion-mystery-radio), on the topic. \n",
    "\n",
    "In addition, we found in the literature surveyed that within the stablecoin universe, the share of Tether continues to drift lower as crypto market participants continue to diversify away from Tether and towards other stablecoins, primarily USDC, a steady trend that started in the summer of 2020. Given the key role that stablecoins play in the crypto ecosystem as the equivalent of “cash” and thus as a source of collateral and liquidity, continued diversification away from Tether would make crypto markets more resilient by reducing overreliance on one stablecoin. The role of stablecoins is currently a [hot topic](https://www.federalreserve.gov/newsevents/speech/files/waller20211117a.pdf) amongst global regulators, policy makers, industry main players and academics.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd8c1db",
   "metadata": {},
   "source": [
    "## <font color= dodgerblue> Rationale of our study </font>\n",
    " \n",
    "#### <font color= dodgerblue> Attacking the problem with on-chain data analysis</font>\n",
    "\n",
    "The difficulty to fit bitcoin within frameworks adopted for traditional asset classes have made commentators like Nouriel Roubini, to argue that there is no way to carry a fundamental analysis of the crypto asset [<sup>3</sup>](#fn3 \"Nouriel Roubini, professor of economics at NYU’s Stern School of Business, entirely disagrees with the idea that something with no income, utility or relationship with economic fundamentals can be considered a store of value, or an asset at all. Please refer to Crypto: A New Asset Class - Goldman Sachs, (2021) - Interview with Nouriel Rubini, p.8 https://www.goldmansachs.com/insights/pages/crypto-a-new-asset-class-f/report.pdf\").\n",
    "He argues that bitcoin and other cryptocurrencies are not assets because assets have some cash flow or utility that can be used to determine their fundamental value: “bitcoin and other cryptocurrencies have no income or utility, so there's just no way to arrive at a fundamental value\". \n",
    "\n",
    "We found in the literature surveyed [9],[10],[11],[12] and [13] that Bitcoin's blockchain provides open-source data as a function of the network's transparency and a real-time global ledger, that publishes data about the network's activity and inner economics; allowing investors to assess [bitcoin's fundamentals](https://www.theinvestorspodcast.com/bitcoin-fundamentals/). On-chain analysis (or blockchain analysis) is an emerging field which examines the fundamental factors of bitcoin and other cryptocurrencies to improve investment strategies and trading decisions. \n",
    "\n",
    "On-chain metrics are those that can be observed by looking at data provided by the blockchain and can be categorized into different areas, such as demand & usage, issuance, security and holder behaviour. Through the collection and study of this data, it is possible to gauge sentiment and investor behaviour, as on-chain data can for example be used to spot crypto market cycles. It is however important to note that crypto market analysis with on-chain indicators is a relatively nascent field and indicators are still being refined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c08346",
   "metadata": {},
   "source": [
    "# <font color= dodgerblue> SECTION II: DATA PREPARATION - BITCOIN CASE STUDY </font> \n",
    "#### <font color= dodgerblue>Time Series Data Preprocessing </font>\n",
    "At this stage, we will deal with the process of data preparation. \n",
    "#### <font color= dodgerblue> Imports & Random Seed</font> \n",
    "\n",
    "We start by importing `Python` packages, modules and required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a11131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import time\n",
    "\n",
    "# Import preprocessor from sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Model Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import cufflinks for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (20,10)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Feature selection & Feature importance\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Time Series cross-validation\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Class encoder\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "# Models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Import from keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Dropout, Dense, LSTM, SimpleRNN\n",
    "\n",
    "# Artificial Neural Nets\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f42dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set a seed value in order to make able to reproduce the results.\n",
    "seed_value = 100\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "#import tensorflow as tf\n",
    "#tf.set_random_seed(seed_value)\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aeed65",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> Data Collection</font> \n",
    "\n",
    "We source our data from [Glassnode.com](https://glassnode.com/) and  we will consider historical BTC data with daily frequency from 2018/02/17  to 2021/10/19. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee9ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bitcoin = pd.read_csv('/Data_Bitcoin/price-ohlc-btc-1h.csv', \n",
    "                      index_col = 0, parse_dates = True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99648252",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bitcoin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bitcoin = Bitcoin.rename(columns = {'c':'Close', \n",
    "                                    'h':'High',\n",
    "                                    'l':'Low', \n",
    "                                    'o':'Open'})\n",
    "Bitcoin.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09476774",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> Visualising Bitcoin Price Fluctuations </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab20363",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bitcoin['Close'].plot(figsize = (16,8),color = 'darkblue');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74cb068",
   "metadata": {},
   "source": [
    "The above graph shows different behaviors of bitcoin's price over time. This will make our \"learning\" more robust as well as give us a chance to test how good the predictions are for a variety of situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca88fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bitcoin['Returns'] = np.log(Bitcoin['Close'] / Bitcoin['Close'].shift(1))\n",
    "Bitcoin.dropna(inplace = True)\n",
    "Bitcoin.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40cac81",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> A new framework to evaluate bitcoin: on-chain analysis </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceec91d",
   "metadata": {},
   "source": [
    "We based part of our research report on findings from [\"On-Chain Data: A New Framework to Evaluate Bitcoin\"](https://ark-invest.com/articles/analyst-research/on-chain-data-bitcoin), where the authors introduce a framework to analyze bitcoin's fundamentals in which they categorize the depth of the analysis within a three-layered pyramid, with lower layers serving as the building blocks for higher layers, as shown below.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd0e9c7",
   "metadata": {},
   "source": [
    "**Figure 2: Three layered pyramid approach to assess Bitcoin's fundamentals** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a84c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url = \"Pyramid n chain data analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda03f2",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> How on-chain data offers a new framework to analyze assets like bitcoin </font>\n",
    " \n",
    "As per Figure 2, in the first layer of the pyramid (from bottom to top), thanks to on-chain analysis, it is possible for investors to monitor the health of the Bitcoin network in real time by extracting raw open-source data from Bitcoin nodes and assess network security, monetary integrity, transparency and usage. For example, Bitcoin’s security is guaranteed by miners, who ensure transactions are verified and irreversible. Cryptocurrency \"mining\" is the process through which the blockchain is secured and new cryptocurrency coins are brought into circulation. Monitoring miner behavior is important for the health of a crypto network, not only as a measure of security, but also because miners are one of the only natural sellers in the market. Declines in hash rate are critical events and have strong implications for the amount of miner-led selling pressure (refer to the [The Great Hash-power Migration](https://insights.glassnode.com/the-week-on-chain-week-27-2021/)). Investors can also monitor Bitcoin’s network activity and usage by tracking the number of active addresses, a proxy for user adoption, in addition to transaction volume, a proxy for economic activity. \n",
    "\n",
    "The data in the second layer of the pyramid above, allows to analyze flows into and out of bitcoin, the behavior of holders, and the cost bases of various cohorts. According to the literature on the subject, on-chain behavior of buyers and sellers can help investors identify bitcoin price inefficiencies. As the value of an asset like bitcoin is a function of demand relative to supply, based on on-chain data, investors can assess the change in demand, and its likely impact on price, by analyzing the behavior of bitcoin buyers and sellers at any point in time. This type of data delves deeper and some have argue that in the long-term; bitcoin’s price might react more to the raw network health data,  but in the short-to medium-term the behavior of buyers and sellers can help investors surface inefficiencies in the pricing and valuation of this \"non-productive asset\".  \n",
    "\n",
    "Finally, in the [layer at the top of the pyramid](https://ark-invest.com/articles/analyst-research/valuing-bitcoin/), there is data leveraging off the two other lower layers, providing relative valuation metrics that identify short-to mid-term inefficiencies in bitcoin’s price. Particularly useful for active management, the top data layer provides buy and sell signals in the crypto market. For example, the Stock to Flow Ratio (S/F) is a model of scarcity which can be applied to predict the future price of an asset. It is defined as the ratio of the current stock of a commodity and the flow of new production, and is applied across many asset classes. Bitcoin's price has historically followed the S/F Ratio, making it a popular model for predicting future bitcoin valuations. This metric was first coined by [PlanB](https://twitter.com/100trillionUSD). For a detailed description see this [article](https://medium.com/@100trillionUSD/modeling-bitcoins-value-with-scarcity-91fa0fc03e25)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3412060b",
   "metadata": {},
   "source": [
    "### <font color= dodgerblue> Relevant on-chain metrics for our study </font>\n",
    "\n",
    "We are going to explore a series of on-chain metrics that will be used in Section III as input to machine learning and deep learning algorithms. For now, let's review on chain metrics data that was available on-line at https://glassnode.com/ in the form of `(.csv)` file and will be included in the list of features selected. \n",
    "    \n",
    "We use on-chain analytics firm Glassnode as on-chain metrics provider, which offers services that convert raw and unorganized blockchain data into user friendly and digestible information. \n",
    "    \n",
    "We will indicate for some metrics the relevance, the rationale behind its use and its role in the investors tool kit to gauge market sentiment, investors behavior, bitcoin top and bottoms (bitcoin cycles), and so on. \n",
    "\n",
    "\n",
    "#### <font color= dodgerblue> Table 1 – List of On-Chain Market Indicators </font>\n",
    "<table>\n",
    "<thead><tr>\n",
    "<th style=\"text-align:left\">Category</th>\n",
    "<th style=\"text-align:left\">Metrics used for Assessment</th>  \n",
    "<th style=\"text-align:left\">Description</th>     \n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>    \n",
    "<td style=\"text-align:left\">Core addresses metrics for the network</td> \n",
    "<td style=\"text-align:left\">New Addresses</td> \n",
    "<td style=\"text-align:left\">The number of unique addresses that appeared for the first time in a transaction of the native coin in the network.</td>    \n",
    "</tr>         \n",
    "<tr>    \n",
    "<td style=\"text-align:left\">Core addresses metrics for the network</td> \n",
    "<td style=\"text-align:left\">Active Addresses</td> \n",
    "<td style=\"text-align:left\">The number of unique addresses that were active in the network either as a sender or receiver. Only addresses that were active in successful transactions are counted.</td> \n",
    "</tr>  \n",
    "<tr>      \n",
    "<td style=\"text-align:left\">Core addresses metrics for the network</td> \n",
    "<td style=\"text-align:left\">Addresses with Non-Zero Balance</td> \n",
    "<td style=\"text-align:left\">The number of unique addresses holding a positive (non-zero) amount of coins.</td>\n",
    "</tr>       \n",
    "<tr>      \n",
    "<td style=\"text-align:left\">Core addresses metrics for the network</td> \n",
    "<td style=\"text-align:left\">Number of Addresses with Balance ≥ 0.1</td> \n",
    "<td style=\"text-align:left\">The number of unique addresses holding at least 0.1 coins.</td>     \n",
    "</tr>        \n",
    "<tr>        \n",
    "<td style=\"text-align:left\">Core address metrics for the network</td> \n",
    "<td style=\"text-align:left\">Number of Addresses with Balance ≥ 1k</td> \n",
    "<td style=\"text-align:left\">The number of unique addresses holding at least 1k coins.</td>   \n",
    "</tr>    \n",
    "    \n",
    "<tr>     \n",
    "<td style=\"text-align:left\">Essential miner metrics</td>\n",
    "<td style=\"text-align:left\">Mean Hash Rate</td>   \n",
    "<td style=\"text-align:left\">The average estimated number of hashes per second produced by the miners in the network.</td>    \n",
    "</tr>        \n",
    "<tr>     \n",
    "<td style=\"text-align:left\">Essential miner metrics</td>\n",
    "<td style=\"text-align:left\">Mining Difficulty</td>   \n",
    "<td style=\"text-align:left\">The current estimated number of hashes required to mine a block. Note: Bitcoin difficulty is often denoted as the relative difficulty with respect to the genesis block, which required approximately 2^32 hashes.</td>    \n",
    "</tr>         \n",
    "<tr>     \n",
    "<td style=\"text-align:left\">Essential miner metrics</td>\n",
    "<td style=\"text-align:left\">Miner Revenue (Total)</td>   \n",
    "<td style=\"text-align:left\">The total miner revenue, i.e. fees plus newly minted coins.</td>    \n",
    "</tr>         \n",
    "<tr>     \n",
    "<td style=\"text-align:left\">Essential miner metrics</td>\n",
    "<td style=\"text-align:left\">Fees (Total)</td>   \n",
    "<td style=\"text-align:left\">The total amount of fees paid to miners. Issued (minted) coins are not included.</td>    \n",
    "</tr>         \n",
    "<tr>     \n",
    "<td style=\"text-align:left\">Essential miner metrics </td>\n",
    "<td style=\"text-align:left\">Number of Blocks Mined</td>   \n",
    "<td style=\"text-align:left\">The number of blocks created and included in the main blockchain in that time period.</td>    \n",
    "</tr>       \n",
    "     \n",
    "<tr>     \n",
    "<td style=\"text-align:left\">On-Chain Exchange Activity</td>\n",
    "<td style=\"text-align:left\">Exchange Inflow Volume (Total)</td>   \n",
    "<td style=\"text-align:left\">The total amount of coins transferred to exchange addresses.</td>    \n",
    "</tr>        \n",
    "<tr>     \n",
    "<td style=\"text-align:left\">On-Chain Exchange Activity</td>\n",
    "<td style=\"text-align:left\">Number of Transfers to Exchanges - All Exchanges</td>   \n",
    "<td style=\"text-align:left\">The total count of transfers to exchange addresses, i.e. the number of on-chain deposits to exchanges.</td>    \n",
    "</tr>         \n",
    "<tr>     \n",
    "<td style=\"text-align:left\">On-Chain Exchange Activity</td>\n",
    "<td style=\"text-align:left\">Exchange Outflow Volume (Total)</td>   \n",
    "<td style=\"text-align:left\">The total amount of coins transferred from exchange addresses.</td>    \n",
    "</tr>         \n",
    "<tr>     \n",
    "<td style=\"text-align:left\">On-Chain Exchange Activity</td>\n",
    "<td style=\"text-align:left\">Exchange Withdrawals</td>   \n",
    "<td style=\"text-align:left\">The total count of transfers from exchange addresses, i.e. the number of on-chain withdrawals from exchanges.</td>    \n",
    "</tr>         \n",
    "<tr>     \n",
    "<td style=\"text-align:left\">On-Chain Exchange Activity</td>\n",
    "<td style=\"text-align:left\">Exchange Balance</td>   \n",
    "<td style=\"text-align:left\">The total amount of coins held on exchange addresses. </td>    \n",
    "</tr>  \n",
    " \n",
    "<tr>     \n",
    "<td style=\"text-align:left\">Top/Bottom Indicators</td>\n",
    "<td style=\"text-align:left\">Net Unrealized Profit/Loss (NUPL)</td>   \n",
    "<td style=\"text-align:left\">Net Unrealized Profit/Loss is the difference between Relative Unrealized Profit and Relative Unrealized Loss. For more information see https://medium.com/glassnode-insights/dissecting-bitcoins-unrealised-on-chain-profit-loss-73e735020c8d. This metric can also be calculated by subtracting realised cap from market cap, and dividing the result by the market cap as described in https://medium.com/@adamant_capital/a-primer-on-bitcoin-investor-sentiment-and-changes-in-saving-behavior-a5fb70109d32</td>    \n",
    "</tr>        \n",
    "<tr>    \n",
    "<td style=\"text-align:left\">Top/Bottom Indicators</td>\n",
    "<td style=\"text-align:left\">Stock-to-Flow Ratio</td>   \n",
    "<td style=\"text-align:left\">The Stock to Flow (S/F) Ratio is a popular model that assumes that scarcity drives value. Stock to Flow is defined as the ratio of the current stock of a commodity (i.e. circulating Bitcoin supply) and the flow of new production (i.e. newly mined bitcoins). Bitcoin's price has historically followed the S/F Ratio and therefore it is a model that can be used to predict future Bitcoin valuations. This metric was first coined by PlanB https://twitter.com/100trillionUSD For a detailed description see this https://medium.com/@100trillionUSD/modeling-bitcoins-value-with-scarcity-91fa0fc03e25 </td>     \n",
    "</tr>          \n",
    "<tr>     \n",
    "<td style=\"text-align:left\">Top/Bottom Indicators</td>\n",
    "<td style=\"text-align:left\">Stock-to-Flow Deflection</td>   \n",
    "<td style=\"text-align:left\">The Stock to Flow (S/F) Deflection is the ratio between the current Bitcoin price and the S/F model. If deflection is ≥ 1 it means that Bitcoin is overvalued according to the S/F model, otherwise undervalued.</td>    \n",
    "</tr>         \n",
    "<tr>     \n",
    "<td style=\"text-align:left\">Top/Bottom Indicators</td>\n",
    "<td style=\"text-align:left\">MVRV Z-Score</td>   \n",
    "<td style=\"text-align:left\">The MVRV Z-Score is used to assess when Bitcoin is over/undervalued relative to its \"fair value\". When market value is significantly higher than realized value, it has historically indicated a market top, while the opposite has indicated market bottoms. Technically, MVRV Z-Score is defined as the ratio between the difference of market cap and realized cap, and the standard deviation of market cap, i.e. (market cap – realized cap) / std(market cap). </td>    \n",
    "</tr>         \n",
    "<tr>     \n",
    "<td style=\"text-align:left\">Top/Bottom Indicators</td>\n",
    "<td style=\"text-align:left\">Puell Multiple</td>   \n",
    "<td style=\"text-align:left\">The Puell Multiple is calculated by dividing the daily issuance value of bitcoins (in USD) by the 365-day moving average of daily issuance value. This metric was created by David Puell https://twitter.com/kenoshaking For a detailed description see https://medium.com/unconfiscatable/the-puell-multiple-bed755cfe358 by https://twitter.com/cryptopoiesis</td>    \n",
    "</tr>         \n",
    "<tr>     \n",
    "<td style=\"text-align:left\">Top/Bottom Indicators</td>\n",
    "<td style=\"text-align:left\">Reserve Risk</td>   \n",
    "<td style=\"text-align:left\">Reserve Risk is defined as price / HODL Bank. It is used to assess the confidence of long-term holders relative to the price of the native coin at any given point in time. When confidence is high and price is low, there is an attractive risk/reward to invest (Reserve Risk is low). When confidence is low and price is high then risk/reward is unattractive at that time (Reserve Risk is high). This metric was created by https://twitter.com/hansthered For more information see https://www.kanaandkatana.com/valuation-depot-contents/2019/5/30/exploration-of-bitcoin-days-destroyed </td>    \n",
    "</tr>      \n",
    "<tr>       \n",
    "</tbody>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5597508",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> On-Chain Market Indicators </font>\n",
    "\n",
    "Investors can source on-chain data to analyze bitcoin since transactions are recorded on-chain, and a whole new set of fundamental indicators is available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ab881",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bitcoin['add_10_k'] = pd.read_csv('Data_Bitcoin/add-10-k-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['add_100_btc'] = pd.read_csv('Data_Bitcoin/add-100-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['blocks_mined'] = pd.read_csv('Data_Bitcoin/blocks-mined-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['coin_dest '] = pd.read_csv('Data_Bitcoin/coin-destroyed-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['dif_rib'] = pd.read_csv('Data_Bitcoin/dif-rib-comp-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['ent_adj_count'] = pd.read_csv('Data_Bitcoin/ent-adj-count-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['ent_vol_total'] = pd.read_csv('Data_Bitcoin/ent-vol-total-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['ex_balance'] = pd.read_csv('Data_Bitcoin/ex-balance-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['ex_bal_usdt'] = pd.read_csv('Data_Bitcoin/ex-balance-usdt-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['ex_deposits'] = pd.read_csv('Data_Bitcoin/ex-deposits-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['ex_inflow_vol'] = pd.read_csv('Data_Bitcoin/ex-inflow-vol-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['ex_inflow_total'] = pd.read_csv('Data_Bitcoin/ex-vol-total-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['net_pos_chan'] = pd.read_csv('Data_Bitcoin/net-pos-chan-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['net_pos_usdt'] = pd.read_csv('Data_Bitcoin/net-pos-usdt-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['netflow_vol'] = pd.read_csv('Data_Bitcoin/netflow-vol-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['netflow_vol_usdt'] = pd.read_csv('Data_Bitcoin/netfl-vol-usdt-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['outflow_mean'] = pd.read_csv('Data_Bitcoin/outflow-mean-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['outflow_total'] = pd.read_csv('Data_Bitcoin/outflow-total-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['withdrawals'] = pd.read_csv('Data_Bitcoin/withdrawals-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['hash_rate'] = pd.read_csv('Data_Bitcoin/hash-rate-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['in_house_vol'] = pd.read_csv('Data_Bitcoin/in-house-vol-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['inflat_rate'] = pd.read_csv('Data_Bitcoin/inflation-rate-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['inter_ex'] = pd.read_csv('Data_Bitcoin/inter-ex-volume-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['liveliness'] = pd.read_csv('Data_Bitcoin/liveliness-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['min_rev_fees'] = pd.read_csv('Data_Bitcoin/min-rev-fees-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['profit_loss'] = pd.read_csv('Data_Bitcoin/real-profit-loss-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['nupl'] = pd.read_csv('Data_Bitcoin/profit-loss-nupl-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['new_adds'] = pd.read_csv('Data_Bitcoin/new-addresses-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['new_entities'] = pd.read_csv('Data_Bitcoin/new-entities-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['num_whales'] = pd.read_csv('Data_Bitcoin/number-of-whales-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['nvt_ratio'] = pd.read_csv('Data_Bitcoin/nvt-ratio-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['nvt_signal'] = pd.read_csv('Data_Bitcoin/nvt-signal-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['utx_profit'] = pd.read_csv('Data_Bitcoin/putx-os-in-profit-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['real_loss'] = pd.read_csv('Data_Bitcoin/realized-loss-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['p_l_ratio'] = pd.read_csv('Data_Bitcoin/realized-p-l-ratio-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['real_profit'] = pd.read_csv('Data_Bitcoin/realized-profit-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['reserve_risk'] = pd.read_csv('Data_Bitcoin/reserve-risk-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['rhodl_ratio'] = pd.read_csv('Data_Bitcoin/rhodl-ratio-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['seller_exhaustion'] = pd.read_csv('Data_Bitcoin/sell-exha-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['sopr'] = pd.read_csv('Data_Bitcoin/sopr-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['s_flow_defl'] = pd.read_csv('Data_Bitcoin/s-flow-deflect-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['supply_loss'] = pd.read_csv('Data_Bitcoin/supply-in-loss-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['s_last_act_1y'] = pd.read_csv('Data_Bitcoin/supply-act-1y-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['total_adds'] = pd.read_csv('Data_Bitcoin/total-addresses-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['tra_count'] = pd.read_csv('Data_Bitcoin/transaction-count-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['utx_created'] = pd.read_csv('Data_Bitcoin/utx-os-created-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']\n",
    "Bitcoin['velocity'] = pd.read_csv('Data_Bitcoin/velocity-btc-24h.csv',index_col = 0, parse_dates = True).dropna()['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f269326d",
   "metadata": {},
   "source": [
    "### <font color= dodgerblue> Adding features for market prediction </font>\n",
    "\n",
    "Cryptocurrencies have shown relatively low correlation to economic fundamental data and other markets, leaving technical analysis and crypto-specific news as the main drivers for analyzing them. In fact, the most dominant form of analysis in cryptocurrency trading/investing is the study of price action or technical analysis; which is the analysis of price signals, charts and indicators to extract information, patterns and probabilities with respect to the supply and demand balance over time. Technical indicators are usually employed to generate buy or sell signals based on observed patterns. This approach often places less relative emphasis on asset fundamentals, and instead focuses on the distillation of all known information into one metric: price. Recently, researchers have focused on technical indicators with machine learning algorithms to predict the price of cryptocurrencies, primarily bitcoin. For the training of our models, we will particulary focus on trend-following (also referred to in academic circles as time-series momentum) which has actively been on investors’ radar for the last few decades. The following momentum-based measures are included in the present study:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba220f5",
   "metadata": {},
   "source": [
    "The table below summarizes the metrics we are including from technical analysis for bitcoin:\n",
    "#### <font color= dodgerblue> Table 1 – List of Technical Market Indicators </font>\n",
    "<table>\n",
    "<thead><tr>\n",
    "<th style=\"text-align:left\">Symbol</th>\n",
    "<th style=\"text-align:left\">Description</th>   \n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">ATR</td>\n",
    "<td style=\"text-align:left\">The average true range (ATR) is a market volatility indicator used in technical analysis. </td>       \n",
    "</tr>    \n",
    "<tr>       \n",
    "<td style=\"text-align:left\">sma14, sma60</td>\n",
    "<td style=\"text-align:left\">A simple moving average is a technical indicator that can aid in determining if an asset price will continue or if it will reverse a bull or bear trend.</td>       \n",
    "</tr>        \n",
    "<tr>    \n",
    "<td style=\"text-align:left\">vol14, vol60</td>\n",
    "<td style=\"text-align:left\">Volatility is used as a measure of a security's riskiness. Typically investors view a high volatility as high risk.</td>    \n",
    "</tr>       \n",
    "<tr>    \n",
    "<td style=\"text-align:left\">sma20,b_upper,b_lower</td>\n",
    "<td style=\"text-align:left\">Bollinger Bands are a technical analysis tool developed for generating oversold or overbought signals.The upper and lower bands are typically 2 standard deviations +/- from a 20-day simple moving average, but can be modified. </td>      \n",
    "</tr>    \n",
    "<tr>         \n",
    "<td style=\"text-align:left\">MOM5D</td>\n",
    "<td style=\"text-align:left\">the momentum of 5 days</td> \n",
    "</tr> \n",
    "<tr>    \n",
    "<td style=\"text-align:left\">STD 21D</td>\n",
    "<td style=\"text-align:left\">the standard deviation of last 21 days</td>\n",
    "</tr>   \n",
    "<tr>    \n",
    "<td style=\"text-align:left\">High, Low, Last, Bid, Ask, volume </td>\n",
    "<td style=\"text-align:left\"> The high and low show the full price range of the period. The term bid and ask (also known as bid and offer) refers to a two-way price quotation that indicates the best potential price at which a security can be sold and bought at a given point in time.The last price represents the price at which the last trade occurred. Volume is an important indicator in technical analysis because it is used to measure the relative significance of a market move </td>   \n",
    "</tr>\n",
    "<tr>     \n",
    "<td style=\"text-align:left\">Returns </td>\n",
    "<td style=\"text-align:left\"> Returns include the tabulation and analysis of past securities prices where trends and patterns may have future predictive power, and are used to predict future returns or to estimate how a security might react to a particular situation.</td>    \n",
    "</tr>\n",
    "<tr>    \n",
    "</tbody>\n",
    "</table>     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3930e4",
   "metadata": {},
   "source": [
    "####  <font color= dodgerblue>Average True Range (ATR) </font>\n",
    "Average true range (ATR) is a volatility indicator. The average true range is an $n$-period average of the true range values. An expanding ATR indicates increased volatility or range of the underlying, while a low ATR value indicates a series of periods with small ranges (quiet days). ATR based exit or stops are popular as it signals changes in volatility. True range is defined as:\n",
    "\n",
    "$TR = max[(high-low), \\space abs(high-close_{prev}), \\space abs(low-close_{prev})]$\n",
    "\n",
    "ATR is defined as \n",
    "\n",
    "$ATR = \\frac{1}{n}\\sum_{i=1}^n TR_i$\n",
    "\n",
    "where $n$ is the number of period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c43da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate average true range (ATR) \n",
    "\n",
    "def ATR(df,n):\n",
    "    \"function to calculate True Range and Average True Range\"\n",
    "    df = df.copy() \n",
    "\n",
    "    df['H-L'] = abs(df['High']-df['Low'])\n",
    "    df['H-PO'] = abs(df['High']-df['Close'].shift(1))\n",
    "    df['L-PO'] = abs(df['Low']-df['Close'].shift(1))\n",
    "    \n",
    "    df['TR'] = df[['H-L','H-PO','L-PO']].max(axis = 1,skipna = False)\n",
    "    df['ATR'] = df['TR'].rolling(n).mean()\n",
    "\n",
    "    df2 = df.drop(['H-L','H-PO','L-PO'],axis = 1)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a092f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATR\n",
    "ATR_Bitcoin = ATR(Bitcoin,21)['ATR']\n",
    "Bitcoin['ATR'] = ATR_Bitcoin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531de156",
   "metadata": {},
   "source": [
    "####  <font color= dodgerblue> Classic Technical Indicators</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc0722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classic Technnical Indicators\n",
    "# Simple Moving Averages\n",
    "# 2 week\n",
    "Bitcoin['sma14'] = Bitcoin['Close'].rolling(14).mean()\n",
    "# 2 month\n",
    "Bitcoin['sma60'] = Bitcoin['Close'].rolling(60).mean()\n",
    "\n",
    "# Rolling Volatility (annualized assuming 365 trading days)\n",
    "# 2 week\n",
    "Bitcoin['vol14'] = Bitcoin['Returns'].rolling(14).std() * np.sqrt(365)\n",
    "# 2 month\n",
    "Bitcoin['vol60'] = Bitcoin['Returns'].rolling(60).std() * np.sqrt(365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8952249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bollinger Bands\n",
    " #20 day simple moving average\n",
    "Bitcoin['sma20'] = Bitcoin['Close'].rolling(20).mean()\n",
    "# Upper band\n",
    "Bitcoin['b_upper'] = Bitcoin['sma20'] + 2 * Bitcoin['sma20'].rolling(20).std()\n",
    "# Lower band\n",
    "Bitcoin['b_lower'] = Bitcoin['sma20'] - 2 * Bitcoin['sma20'].rolling(20).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95beeb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum\n",
    "MOM5D = np.around([Bitcoin['Close'][t] - Bitcoin['Close'][t-5] \n",
    "                   for t in range(5,len(Bitcoin['Close']))],3)\n",
    "\n",
    "# For these features we have to reduce the sample size due to min{len(MOM5D),\n",
    "# len(STD21D)}<len(Bitcoin)\n",
    "N = len(MOM5D)\n",
    "Bitcoin = Bitcoin[::- 1].iloc[range(0,N)] \n",
    "Bitcoin = Bitcoin[::- 1] \n",
    "Bitcoin['MOM5D'] = MOM5D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0303a54",
   "metadata": {},
   "source": [
    "####  <font color= dodgerblue> Adding lags</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e504da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop NANs\n",
    "Bitcoin = Bitcoin.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a22ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of days lagged data to use for each sample\n",
    "lags = 5\n",
    "\n",
    "# Empty list to store feature column names\n",
    "cols = [] \n",
    "\n",
    "features = list(Bitcoin.keys())       \n",
    "\n",
    "# For each feature\n",
    "for f in features:\n",
    "    for lag in range(1, lags + 1):\n",
    "        col = f'{f}_lag_{lag}'\n",
    "        Bitcoin[col] = Bitcoin[f].shift(lag)\n",
    "        cols.append(col)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535850bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop NANs\n",
    "Bitcoin = Bitcoin.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5b8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Bitcoin.copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc38ab",
   "metadata": {},
   "source": [
    "Below is the list of features we are considering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15c7815",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db6437c",
   "metadata": {},
   "source": [
    "Predicting tomorrow’s market direction can be framed as a classification problem with the set of categories limited to, for example, “up” and “down” or “+1” and “-1” or “1” and “0”. We set up the dataframe with the target variable, which is the direction of the future daily movement of BTC and can be mathematically interpreted as the sign of the return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb031cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our response feature will be the sign of BTC's returns (i.e. daily directional movement)\n",
    "Y = pd.DataFrame(list(np.where(Bitcoin['Returns'] >= 0, 1, -1))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aa506a",
   "metadata": {},
   "source": [
    "Feature scaling can help algorithms converge to local / global minima efficiently. We will use `MinMaxScaler` scaler from the `scikit-learn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4697cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We scale the data \n",
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "# We let X as a dataframe\n",
    "X = pd.DataFrame(scaled_X,columns = list(Bitcoin.keys()),\n",
    "                 index = Bitcoin.index)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986f2766",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> Splitting & Normalizing the Dataset</font> \n",
    "\n",
    "#### <font color= dodgerblue>Split the data</font>\n",
    "A critical part of machine learning is having a clear distinction between the data that will be used to train the model and the data that will be used to assess the predictive power of the model. Therefore, we will use a Train/Test split, with a Train set of 70% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b757427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% train/test split\n",
    "split = int(len(X) * 0.7)\n",
    "\n",
    "# We transform Y to a binary classification problem's values (0 y 1)\n",
    "encoder = LabelEncoder() \n",
    "encoder.fit(Y) \n",
    "encoded_Y = encoder.transform(Y) \n",
    "# We transform encoded_Y into a dataframe in order to use .iloc and being able to make the \n",
    "# train/test split\n",
    "Y = pd.DataFrame(encoded_Y, columns = ['Column_A'], index = Y.index) \n",
    "\n",
    "# Create train data set\n",
    "# We have to twist the dataset\n",
    "X_train, y_train = X[:split], Y[:split]\n",
    "# Test data after train split\n",
    "X_test, y_test = X[split+3:], Y[split+3:]\n",
    "\n",
    "# Scale the features MinMax for training and test datasets\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "# We change from array to dataframe\n",
    "X_train = pd.DataFrame(scaled_X_train,columns = X.columns,index = X.iloc[:split].index)\n",
    "y_train = pd.DataFrame(y_train,columns = Y.columns,index = Y[:split].index)\n",
    "X_test = pd.DataFrame(scaled_X_test,columns = X.columns,index = X[split+3:].index)\n",
    "y_test = pd.DataFrame(y_test,columns = Y.columns,index = Y[split+3:].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f4fff",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> Reshaping the data for LSTM</font>\n",
    "\n",
    "We need to reshape the data as LSTM networks consume input in a 3-dimensional array in the form of number of samples, number of time steps and number of features, while our `x_train data` is a 2-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the Data for LSTM\n",
    "# reshaping into 3D Array\n",
    "X_train_LSTM = np.array(scaled_X_train).reshape(len(scaled_X_train),1,len(list(X.keys())))\n",
    "X_test_LSTM = np.array(scaled_X_test).reshape(len(scaled_X_test),1,len(list(X.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe4c944",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> SECTION III: BUILDING AND TRAINING MACHINE LEARNING & DEEP LEARNING MODELS (Classifiers) </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0544c6d",
   "metadata": {},
   "source": [
    "A major revolution and profound changes are happening in the [investment management\n",
    "industry](https://hbr.org/2019/12/what-machine-learning-will-mean-for-asset-managers), as professional traders and fund managers are increasingly implementing quantitative investing techniques and adopting new methods of analysis such as those based on artificial intelligence and machine learning, allowing them to create more realistic models that can adapt better to changing market conditions. In that sense, machine learning can be deployed as a tool into different steps of the investment process [14]; by enhancing signal generation, portfolio construction and risk management, in order to sharpen a current alpha-generation system or existing quant strategies but it is also used to make discretionary call/trade execution. \n",
    "\n",
    "According to expert Dr. Yves J. Hilpisch, “deep learning algorithms have generated breakthroughs in recent years in fields that have proven resistant over pretty long periods of time against standard statistical or mathematical methods”[15]. As a matter of fact, artificial intelligence and in particular advanced artificial intelligence such as deep learning has been able to make predictions with superhuman accuracy. A deep learning method takes a black-box like approach to predicting asset market movements as the algorithm learns by itself which features to select and it assigns the correspondent weights. \n",
    "\n",
    "We assume the prediction problem of bitcoin movements can be modeled as a binary classification problem using neural networks and other machine learning algorithms. We built in Section II an analytical framework for market movement prediction based on a combination of engineered data features, technical trading indicators and on-chain metrics as input to our classification algorithms or classifiers. We now explore, study and test the robustness of certain predictors out of sample such as logistic regression, support vector machines (SVM) and artificial neural networks; in particular the Multi Layers Perceptron (MLP) and Long Short-Term  Memory (LSTM) neural networks using `Keras` Python package to the classification problem of bitcoin (BTC) daily price direction prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c441403",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue>  MACHINE LEARNING ALGORITHMS </font> \n",
    "We test the performance of three models (classifiers): the Naive Gaussian Bayes Classifier, Logistic Regression and Support Vector Machine (SVM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dccd43",
   "metadata": {},
   "source": [
    "For each model, we will show the \"score” associated to its performance in the test set. We will also use the python time function during the training of each model. We define an empty list where we will save our trainings times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e3f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e7da2c",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> Naive Gaussian Bayes Classifier </font>  \n",
    "\n",
    "Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of features given the value of the class variable. The different naive Bayes classifiers differ mainly by the assumptions they make regarding the distribution of $P(x_i \\mid y)$.\n",
    "- The `GaussianNB` module implements the Gaussian Naive Bayes algorithm for classification that we have added from `sklearn.naive_bayes import GaussianNB` in the import cell above. \n",
    "- In a Gaussian Naive Bayes classification we assume that data for each feature is distributed from a Gaussian distribution: \\begin{equation} P(x_i | y) = \\frac{1}{\\sqrt{2\\pi\\sigma_y^2}} \\exp \\left( - \\frac{(x_i - \\mu_y)^2}{2 \\sigma^2{y}} \\right) \\end{equation}\n",
    "- The parameters $\\sigma_y$ and  $\\mu_y$ are estimated using maximum likelihood.\n",
    "\n",
    "We will use `GaussianNB` classifier's fit method to learn the training and test data set. \n",
    "\n",
    "[In scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html?highlight=naive%20gaussian%20bayes%20classifier#):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e4d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd55b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_gauss = time.time()\n",
    "gauss.fit(X_train, y_train)\n",
    "end_gauss = time.time()\n",
    "gauss_runtime = end_gauss - start_gauss\n",
    "\n",
    "print('Runtime:',gauss_runtime)\n",
    "print(\"score on test: %.3f\"  %gauss.score(X_test, y_test))\n",
    "print(\"score on train: %.3f\" %gauss.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074995bf",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue>  Logistic Regression </font> \n",
    "\n",
    "Logistic regression, despite its name, is a linear model for classification rather than regression. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a [logistic function](https://en.wikipedia.org/wiki/Logistic_function). A logistic regression function can be considered a swallow neural network with just one neuron with a sigmoid activation function.\n",
    "\n",
    "- We use a sigmoid function:\n",
    "\\begin{equation}\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "\\end{equation}\n",
    "\n",
    "- for a single training pair $(𝐱,𝑦)$ , we assume:\n",
    "\\begin{equation}\n",
    "P(Y=1 | \\mathbf{X}=\\mathbf{x}) = \\sigma(z)\n",
    "\\end{equation}\n",
    "\n",
    "- where:\n",
    "\\begin{equation}\n",
    "z = w_0 + \\sum_{i=1}^m w_i x_i\n",
    "\\end{equation}\n",
    " \n",
    "\n",
    "\n",
    "[In scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html?highlight=naive%20gaussian%20bayes%20classifier#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b652946",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "start_LR = time.time()\n",
    "LR.fit(X_train, y_train)\n",
    "end_LR = time.time()\n",
    "LR_runtime = end_LR - start_LR\n",
    "\n",
    "print('Runtime:',LR_runtime)\n",
    "print(\"score on test: %.3f\" % LR.score(X_test, y_test))\n",
    "print(\"score on train: %.3f\" % LR.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f64195",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue>  Support Vector Machine (SVM)</font> \n",
    "\n",
    "Support vector machines (SVMs) are a supervised-learning classication technique where we have classified data represented by vectors of features. This method divides data according to which side of a hyperplane in feature space each point lies. A good separation is achieved by the hyperplane that has the largest distance to the nearest training data points of any class (so-called functional margin), since in general the larger the margin the lower the generalization error of the classifier. \n",
    "\n",
    "[`LinearSVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) is a class capable of performing binary classification on a dataset for the case of a linear kernel. Note that `LinearSVC` does not accept parameter kernel, as this is assumed to be linear.\n",
    "\n",
    "The primal problem can be equivalently formulated as:\n",
    "\n",
    "$\\min_ {w, b} \\frac{1}{2} w^T w + C \\sum_{i=1}\\max(0, 1 - y_i (w^T \\phi(x_i) + b))$,\n",
    "\n",
    "where we make use of the hinge loss. This is the form that is directly optimized by `LinearSVC`, but this form does not involve inner products between samples, so the famous kernel trick cannot be applied. This is why only the linear kernel is supported by `LinearSVC` ( $\\phi$ is the identity function).\n",
    "\n",
    "\n",
    "In scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcede81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(C = 100)\n",
    "\n",
    "start_svm = time.time()\n",
    "svm.fit(X_train, y_train)\n",
    "end_svm = time.time()\n",
    "svm_runtime = end_svm - start_svm\n",
    "\n",
    "print('Runtime:',svm_runtime)\n",
    "print(\"score on test: %.3f\" % svm.score(X_test, y_test))\n",
    "print(\"score on train: %.3f\" % svm.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7d0bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes.append(svm_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c34d87e",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue>  DEEP LEARNING MODELS</font> \n",
    "#### <font color= dodgerblue>  Using Deep Neural Networks to Predict Market Direction \n",
    "    \n",
    "The main considerations that led us to explore the use of neural nets for the binary classification problem of predicting bitcoin price direction are:\n",
    "\n",
    "* Neural networks are at their heart a method to detect patterns. \n",
    "* The potential of neural networks to discover hidden and complex structure in financial data is intriguing.\n",
    "* Differing neural networks architectures offer the potential to outperform competing factor model designs.\n",
    "* Although neural nets, and specifically deep neural nets, offer extreme flexibility, the benefit is accompanied by a significant risk of **overfitting**\n",
    "* We need to be aware of the limitations of neural networks, and be thoughtful about adapting them to the problems we face. \n",
    "    \n",
    "Despite the vast majority of the problems encountered in finance can be adequately addressed by linear models, the need for neural nets comes from that they can potentially improve the solution to the existing problems that can be \"adequately\" modelled linearly. In the context of investing, this added value is called ‘computational alpha’. As the cost of computational power is becoming increasingly inexpensive, the return on investment on neural nets can be sizable even with moderate improvements in risk adjusted rate of return.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294a51aa",
   "metadata": {},
   "source": [
    "When building neural networks, we must be careful not to use too many layers and neurons, specifically if the data set is not particularly large. Many parameters will inevitably improve in sample performance (on the train set) but will also lead to the risk of overfitting. Additionally, the training process will require much more computational power, thus increasing the risk of non-convergence. Another important reason to avoid the use of overly complex networks, and to use methods that reduce overfitting such as dropout, is the fact that we are training with financial time series that often have noisy data (patterns that are not essential).     \n",
    "\n",
    "#### <font color= dodgerblue> Multilayer Perceptron (MLP Classifier)</font> \n",
    "\n",
    "Multi-layer Perceptron (MLP) is a supervised learning algorithm that learns a function $f(\\cdot): R^m \\rightarrow R^o$\n",
    "by training on a dataset, where $m$ is the number of dimensions for input and $o$ is the number of dimensions for output. Given a set of features $X = {x_1, x_2, ..., x_m}$ and a target $y$, it can learn a non-linear function approximator for either classification or regression. It is different from logistic regression, in that between the input and the output layer, there can be one or more non-linear layers, called hidden layers.\n",
    "\n",
    "An MLP consists of at least three layers of nodes: an input layer, a hidden layer and an output layer. Except for the input nodes, each node is a neuron that uses a non-linear activation function. MLP utilizes a supervised learning technique called backpropagation[<sup>3</sup>]( #fn3 \"Backpropagation is the primary means by which a neural network's weights are determined during training. Backpropagation works by calculating a weight change amount ($v_t$) for every weight($\\theta$, theata) in the neural network. This value is subtracted from every weight by the following equation: $\\theta_t = \\theta_{t-1} - v_t$\") for training. We have noticed that a batch_size = 1 and epochs = 39 returns a decent model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57deb04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_MLP(optimizer, activation, loss, metrics):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,  activation = activation))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer = optimizer, \n",
    "                  loss = loss, \n",
    "                  metrics = metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "MLP = model_MLP(optimizer = 'adam',\n",
    "                activation = 'relu',\n",
    "                loss = 'binary_crossentropy',\n",
    "                metrics = ['binary_accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea109b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_MLP = time.time()\n",
    "history_MLPV = MLP.fit(X_train, y_train, batch_size = 1, epochs = 39 , verbose = 0,\n",
    "                      validation_split = 0.33, shuffle = False)\n",
    "end_MLP = time.time()\n",
    "MLP_runtime = end_MLP - start_MLP\n",
    "\n",
    "print('Runtime:',MLP_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f962af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes.append(MLP_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31294e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MLP.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a61e5b",
   "metadata": {},
   "source": [
    "The MLP model will train 3,905 parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdd0a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "fig, axs = plt.subplots(1,2)\n",
    "fig.suptitle('MLP model training performance', fontsize = 20)\n",
    "axs[0].plot(history_MLP.history['binary_accuracy'])\n",
    "axs[0].plot(history_MLP.history['val_binary_accuracy'])\n",
    "axs[0].set_title('Model accuracy', fontsize = 15)\n",
    "axs[0].set_ylabel('binary_accuracy')\n",
    "axs[0].set_xlabel('epoch')\n",
    "axs[0].legend(['train', 'validation'], loc = 'upper left')\n",
    "axs[1].plot(history_MLP.history['loss'])\n",
    "axs[1].plot(history_MLP.history['val_loss'])\n",
    "axs[1].set_title('Model loss', fontsize = 15)\n",
    "axs[1].set_ylabel('loss')\n",
    "axs[1].set_xlabel('epoch')\n",
    "axs[1].legend(['train', 'validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7032cae3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### <font color= dodgerblue> Long Short Term Memory (LSTM) Neural Nets </font> \n",
    "We use the Long short-term memory (LSTM) version of recurrent neural networks to predict the price movement of bitcoin. LSTM algorithm is capable of learning long-term dependencies and has demonstrated to achieve state-of-the-art results in time series forecasting. LSTM neural networks' topology is different from classical networks and makes them useful for working with data that has a short and long-term time dependence, such as financial time series.\n",
    "\n",
    "\n",
    "\n",
    "First, we define the LSTM network by initializing the Keras Sequential model. Then we will add two LSTM layers and adjust the dropout percentage (drop_pct) which is a regularization method that adds information to reduce overfitting and to improve the performance of the model. Finally, we will add two dense layers for the output.\n",
    "We tune the hyperparameters that can be calibrated to improve performance which are the number of epochs and batch size. We have noticed that by setting the evaluation batch size to a value greater or equal to the training batch size  `batch_size=len(X_train_LSTM)` and epochs = 60 returns a decent model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3b5df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_LSTM_(optimizer,activation,loss,metrics):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(units = 256, input_shape = (X_train_LSTM.shape[1],X_train_LSTM.shape[2]),\n",
    "                   return_sequences = True)) \n",
    "    model.add(Dropout(0.4, seed = seed_value))\n",
    "\n",
    "    model.add(LSTM(units = 256, return_sequences = True))\n",
    "    model.add(Dropout(0.4, seed = seed_value))\n",
    "\n",
    "    model.add(LSTM(units = 64, return_sequences=False))\n",
    "    model.add(Dropout(0.4, seed = seed_value))\n",
    "\n",
    "    model.add(Dense(64,  activation = activation))\n",
    "  \n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "  \n",
    "    model.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the Model\n",
    "model_LSTM = model_LSTM_(optimizer = 'adam',\n",
    "                         activation = 'relu',\n",
    "                         loss = 'binary_crossentropy',\n",
    "                         metrics = ['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6074a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_LSTM = time.time()\n",
    "history_LSTM = model_LSTM.fit(X_train_LSTM, y_train, batch_size = len(X_train_LSTM), \n",
    "                              epochs = 60, verbose = 0, validation_split = 0.33, shuffle = False)\n",
    "end_LSTM = time.time()\n",
    "LSTM_runtime = end_LSTM - start_LSTM\n",
    "# len(X_train_LSTM)\n",
    "print('Runtime:',LSTM_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec69482",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes.append(LSTM_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bb042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_LSTM.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edbac5a",
   "metadata": {},
   "source": [
    "##### <font color= dodgerblue>Architecture of Network</font> \n",
    "The LSTM model consists of\n",
    "\n",
    "- 256 neurons\n",
    "- hidden layers\n",
    "- 40% dropout precentage\n",
    "\n",
    "In total, the model will train 935,297 parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba36f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "fig, axs = plt.subplots(1,2)\n",
    "fig.suptitle('LSTM model training performance', fontsize = 20)\n",
    "axs[0].plot(history_LSTM.history['binary_accuracy'])\n",
    "axs[0].plot(history_LSTM.history['val_binary_accuracy'])\n",
    "axs[0].set_title('Model accuracy', fontsize = 15)\n",
    "axs[0].set_ylabel('binary_accuracy')\n",
    "axs[0].set_xlabel('epoch')\n",
    "axs[0].legend(['train', 'validation'], loc = 'upper left')\n",
    "axs[1].plot(history_LSTM.history['loss'])\n",
    "axs[1].plot(history_LSTM.history['val_loss'])\n",
    "axs[1].set_title('Model loss', fontsize = 15)\n",
    "axs[1].set_ylabel('loss')\n",
    "axs[1].set_xlabel('epoch')\n",
    "axs[1].legend(['train', 'validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e337db",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> Market Prediction </font> \n",
    "    \n",
    "As measures of the performance of both neural nets, we will use the [`binary_accuracy`](https://keras.io/api/metrics/accuracy_metrics/#binaryaccuracy-class) and the [`binary_crossentropy`](https://keras.io/api/metrics/probabilistic_metrics/#binarycrossentropy-class). These metrics are part of the tool kit when performing classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "y_pred_MLP = MLP.predict(X_test, batch_size = 1)\n",
    "# LSTM\n",
    "y_pred_LSTM = model_LSTM.predict(X_test_LSTM, batch_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f14a3e0",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> Prediction metrics on the test set </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4abefd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "results_MLP = MLP.evaluate(X_test, y_test)\n",
    "print('MLP: [binary_crossentropy, binary_accuracy] =', results_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3714304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "results_LSTM = model_LSTM.evaluate(X_test_LSTM, y_test)\n",
    "print('LSTM: [binary_crossentropy, binary_accuracy] =', results_LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd26e08c",
   "metadata": {},
   "source": [
    "So far, all models have managed to predict with an accuracy over 50% which is promising. SVM is by far the outperfoming classifer while LR and neural nets lagging quite behind, both in performance and time of convergence. We will try to make some adjustments in order to improve the accuracy of our models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfff57d",
   "metadata": {},
   "source": [
    "### <font color= dodgerblue> Exploratory Data Analysis - \n",
    "\n",
    "A natural question is to try to understand what features contributed to the performance of the models deployed. The next step once we have found which features are important, is to inquire about what triggers a change in importance over time of those features and if whether or not; these regime switches can be predicted. This is  however out of the scope of our study.\n",
    "\n",
    "The classes in the `sklearn.feature_selection` module can be used for feature selection/dimensionality reduction on sample sets, either to improve estimators’ accuracy scores or to boost their performance on very high-dimensional datasets.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581cf8e6",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> Feature Selection & Feature Importance</font> \n",
    "\n",
    "\n",
    "In the words of Marcos Lopez de Prado, \"Feature importance is a true research tool, because it helps us understand the nature of the patterns uncovered by the ML algorithm, regardless of their monetization. Critically, feature importance is derived ex-ante, before the historical performance is simulated\" [17].\n",
    "\n",
    "Feature Selection is the process of selecting optimal number of features from a larger set of features. Feature selection methods are intended to reduce the number of input variables to those that are believed to be most useful to a model in order to predict the target variable. \n",
    "\n",
    "##### <font color= dodgerblue> Feature selection using SelectKBest (For classification: f_classif)</font>\n",
    "Univariate feature selection works by selecting the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator and, in our case, `SelectKBest` removes all but the $k$ highest scoring features. `f_classif` refers to the methods based on F-test that estimate the degree of linear dependency between two random variables and assume a linear relationship between the feature and the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply SelectKBest class to order the most relevant features with respect to f_classif\n",
    "bestfeatures = SelectKBest(score_func = f_classif, k = len(X.keys()))\n",
    "fit = bestfeatures.fit(X,Y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "# we concatenate two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis = 1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(len(X.keys()),'Score'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d3a39",
   "metadata": {},
   "source": [
    "**We select the top 25 features** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b45a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feat = list(featureScores.nlargest(25,'Score')['Specs'])\n",
    "for i in list(featureScores['Specs']):\n",
    "    if(i not in best_feat):\n",
    "        X.drop(i,axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29823e9",
   "metadata": {},
   "source": [
    "According to this slection features method, amongst the more relevant metrics are: MOM5D, Open, Low, High, Net Unrealized profit loss (NUPL), Hash Rate, Exchange balance percent, Addresses with balance over 100 BTC, Exchange Withdrawals and difficulty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191b1ca1",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> Tree-based feature selection (Feature Importance) </font> \n",
    "\n",
    "Tree-based estimators (see the `sklearn.tree` module and forest of trees in the `sklearn.ensemble module`) can be used to discard irrelevant features [15]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3974ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use inbuilt class feature_importances of tree based classifiers\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,Y)\n",
    "print(model.feature_importances_) \n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index = X.columns)\n",
    "feat_importances.nlargest(len(X.keys())).plot(kind = 'barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837308dd",
   "metadata": {},
   "source": [
    "We use this feature selection method in order to identify relevant features and constrast them with those obtained by SelectKBest. The more relevant metrics in this case are: MOM5D, inter_exchange_volume, velocity and the nvt ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b60a1b",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> Correlation Matrix </font>\n",
    "Correlation heatmap is a graphical representation of correlation matrix representing correlation between different variables. We plot a Correlation Heatmap using Python `Seaborn` library for different columns in Pandas dataframe to understand predictive relationship between response and predictor variables. In case there is strong positive or negative correlation, the predictor variables can be considered as features for training the models. If the correlation between predictor variables comes out to be greater than 0.7 or less than -0.7, one of these variables can be [removed as predictor variable when training the model](https://stackoverflow.com/questions/17778394/list-highest-correlation-pairs-from-a-large-correlation-matrix-in-pandas.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0038b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Matrix with Heatmap\n",
    "# We will observe correlations of each features within the dataset\n",
    "corrmat = X.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize = (20,20))\n",
    "#plot heat map\n",
    "g = sns.heatmap(X[top_corr_features].corr(),annot = True,cmap = \"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07aec79",
   "metadata": {},
   "source": [
    "##### <font color= dodgerblue> Observations from the correlation matrix </font> \n",
    "We have noticed that selecting features that have very low correlation improve the performance of neural nets.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7a2073",
   "metadata": {},
   "source": [
    "\n",
    "#### We then can feed our models with the data and compare the results:\n",
    "#### <font color= dodgerblue> Naive Gaussian Bayes Classifier </font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971ed0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_gauss = time.time()\n",
    "gauss.fit(X_train, y_train)\n",
    "end_gauss = time.time()\n",
    "gauss_runtime = end_gauss - start_gauss\n",
    "\n",
    "print('Runtime:',gauss_runtime)\n",
    "print(\"score on test: %.3f\"  %gauss.score(X_test, y_test))\n",
    "print(\"score on train: %.3f\" %gauss.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b391cdd7",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue>  Logistic Regression </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c30734",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "start_LR = time.time()\n",
    "LR.fit(X_train, y_train)\n",
    "end_LR = time.time()\n",
    "LR_runtime = end_LR - start_LR\n",
    "\n",
    "print('Runtime:',LR_runtime)\n",
    "print(\"score on test: %.3f\" % LR.score(X_test, y_test))\n",
    "print(\"score on train: %.3f\" % LR.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2a6f7",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue>  Support Vector Machine (SVM)</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(C = 100)\n",
    "\n",
    "start_svm = time.time()\n",
    "svm.fit(X_train, y_train)\n",
    "end_svm = time.time()\n",
    "svm_runtime = end_svm - start_svm\n",
    "\n",
    "print('Runtime:',svm_runtime)\n",
    "print(\"score on test: %.3f\" % svm.score(X_test, y_test))\n",
    "print(\"score on train: %.3f\" % svm.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcf325d",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> Multilayer Perceptron (MLP Classifier)</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd97f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_MLP = time.time()\n",
    "history_MLP = MLP.fit(X_train, y_train, batch_size = 1, \n",
    "                      epochs = 39, verbose = 0, validation_split = 0.33, \n",
    "                      shuffle = False)\n",
    "end_MLP = time.time()\n",
    "MLP_runtime = end_MLP - start_MLP\n",
    "\n",
    "print('Runtime:',MLP_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58873de",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> Long Short Term Memory (LSTM) Neural Nets </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab7a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_LSTM = time.time()\n",
    "history_LSTM = model_LSTM.fit(X_train_LSTM, y_train, \n",
    "                              batch_size = len(X_train_LSTM), epochs = 50, \n",
    "                              verbose = 0, validation_split = 0.33, shuffle = False)\n",
    "end_LSTM = time.time()\n",
    "LSTM_runtime = end_LSTM - start_LSTM\n",
    "# len(X_train_LSTM)\n",
    "print('Runtime:',LSTM_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51569d24",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> Prediction  </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f2c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "y_pred_MLP = MLP.predict(X_test, batch_size = 1)\n",
    "# LSTM\n",
    "y_pred_LSTM = model_LSTM.predict(X_test_LSTM, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e0fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "results_MLP = MLP.evaluate(X_test, y_test)\n",
    "print('MLP: [binary_crossentropy, binary_accuracy] =', results_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "results_LSTM = model_LSTM.evaluate(X_test_LSTM, y_test)\n",
    "print('LSTM: [binary_crossentropy, binary_accuracy] =', results_LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8cec0b",
   "metadata": {},
   "source": [
    "### <font color= dodgerblue> SECTION IV: VECTORIZED BACKTEST </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0dd76f",
   "metadata": {},
   "source": [
    "A backtest is a historical simulation of how a strategy would have performed should it have been run over a past period of time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b14d4a",
   "metadata": {},
   "source": [
    "#### <font color= dodgerblue> Comparison of models</font> \n",
    "We define a dictionary; `models`, to store the comparison of the returns for the different machine learning and deep learning models. Then for each model in `models`, we use the `predict_class()` method to forecast a value of either 0 or 1. Then using `Numpy`, we convert 0 values into -1, and simulating a long position when an upwards move is predicted and a short position when a downwards move is predicted. The final step is the calculation of the strategy return of each model by multiplying the log return, `Bitcoin['Returns']`, by the position.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23e7f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'gauss': gauss,\n",
    "          'LR': LR,\n",
    "          'svm': svm,\n",
    "          'MLP': MLP,\n",
    "          'model_LSTM': model_LSTM} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1523df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame()\n",
    "for i in range(0,len(models)-1):\n",
    "    predictions[list(models.keys())[i]] = np.where(models[list(models.keys())\n",
    "                                                          [i]].predict(X_test) >= 0.5,1,0)\n",
    "predictions[list(models.keys())[4]] = np.where(models[list(models.keys())[4]].\n",
    "                                               predict(X_test_LSTM, batch_size = 1) >= 0.5,1,0)\n",
    "predictions.index = X_test.index   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8498da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(models)):\n",
    "    X_test['prediction_' + list(models.keys())[i]] = np.where(predictions[list(models.keys())\n",
    "                                                                        [i]] >= 0.5,1,0)\n",
    "    X_test['strategy' + list(models.keys())[i]] = X_test['prediction_' + \n",
    "                                                        list(models.keys())[i]] * \n",
    "    Bitcoin[split+3:]['Returns']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9663f54e",
   "metadata": {},
   "source": [
    "Below, we compare the performance of the 5 models vs the passive benchmark return, which assumes the investor holds a long unit position in bitcoin for the entire `test`data range and we plot the gross strategy returns of each supervised learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796f2d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategies \n",
    "for i in range(0,len(models)):\n",
    "    plt.plot(X_test['strategy' + list(models.keys())[i]].cumsum().apply(np.exp),\n",
    "             marker = '.', label = list(models.keys())[i])\n",
    "    print('Gross returns using strategy_' + list(models.keys())[i] + ': %f.3' \n",
    "          % np.exp(X_test['strategy' + list(models.keys())[i]].sum()))   \n",
    "\n",
    "print('Passive benchmark return_: %f.3' %np.exp(Bitcoin[split+3:]['Returns'].sum()))    \n",
    "plt.plot(Bitcoin[split + 3:]['Returns'].cumsum().apply(np.exp),marker = '.',\n",
    "         label = 'Passive Benchmark',color = 'black')\n",
    "plt.title('Gross Strategy Returns')\n",
    "# axis labels\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('gross returns')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a3f1f6",
   "metadata": {},
   "source": [
    "The results show that all algorithmic trading strategies outperform the passive benchmark which is promising! The excitment comes from the fact that strategies based on SVM, LR and MLP outperfom the passive benchmark during a period of stress, the beginning of the pandemic in 2020 which was a very difficult time for the world, financial markets and the crypto space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546fadf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <font color= dodgerblue> SECTION V: CONCLUSION</font> \n",
    "\n",
    "In this programmatic project we compared a number of supervised learning models and tested the robustness of these predictors out of sample such as logistic regression, support vector machines (SVM), Multi Layer Perceptron (MLP) and Long Short-Term Memory (LSTM) neural networks. We also presented a starting point with machine learning and deep learning algorithms and their application to the classification problem of bitcoin (BTC) daily price direction prediction using `Keras` Python package.  \n",
    "\n",
    "Ultimately, after testing different machine learning models across multiple factor datasets, standardisation techniques, layer architectures, activation functions, optimisers, loss functions and frequencies; we still lack a bit of confidence in the resulting expected returns despite the results have been encouraging. We strongly believe more work on model resolution, stability, capacity, repeatability, single model vs ensemble, dropout and regularization needs to be done before we can justify an investment based on these models.\n",
    "\n",
    "Innovation in the field continues at an exponential rate with novel ideas being proposed constantly and we believe that with time we may find that some of these yet to be discovered techniques are the key to unlocking a new investment model. Decentralized finance (DeFi) protocols competing with traditional finance products, the Metaverse and NFTs (non-fungible token) are segments from the crypto market viewed as having the highest growth potential [18].\n",
    "    \n",
    "##### <font color= dodgerblue>Extensions to the present study:</font> \n",
    "    \n",
    "**From off-line algorithm to online algorithm (real-time trading)**\n",
    "So far we have only tested offline algorithms which use a limited data set. In offline learning, we start with a certain amount of data available while in online learning we are continuously updating our models with new batches of data.  \n",
    "    \n",
    "**Derivatives and bitcoin's price direction prediction problem**\n",
    "Since bitcoin have shown low correlation to economic fundamental data and other markets (until 2020), we should then turn our attention particularly to academic research on bitcoin's derivatives market for clues about information, relationships, data and features that could help us in the exercise of accurately predicting the movement of this cryptocurrency. Crypto assets and their derivatives have become the ideal testing ground for studying market microstructure with bid-ask spreads, inter-exchange spreads and relative trading volumes becoming important determinants of price discovery. Some studies such as (Alexander, Choi, Massie, et al.; 2020) and (Alexander, Choi, Park, et al.; 2020) use the derivatives data to examine the price discovery process through the cryptocurrency market. Further research could be performed about relevant metrics from the derivatives market that could help us in the exercise of predicting bitcoin price direction. Perhaps it would be interesting to explore metrics such as futures funding rates, futures open interest, crypto-margined futures open and liquidations.  \n",
    "    \n",
    "**Include more models for the prediction excercise**\n",
    "Machine learning approaches (e.g., Artificial Neural Nets, support vector machines, and tree-based methods) are often able to capture nonlinear patterns, including interactions between input variables. This feature can enhance single-factor and multifactor signal construction by capturing higher-order relations and complex information contained in input variables. However, the natural language processing (NLP) branch of machine learning tools can allow creating factors that are based on textual information (e.g.,corporate reports, news articles, social media posts, and conference call transcripts). The evidence suggests  that  NLP  tools  can  successfully  extract  information  that  is  relevant  for  the  prediction of returns. This is usually carried out by either training the NLP model to make return forecasts directly or by using the model to capture sentiment and tone from the text. This should be another line of research quite interesting given the amount of headlines related to the crypto space, particularly bitcoin.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac2f095",
   "metadata": {},
   "source": [
    "**Footnotes**\n",
    "\n",
    "[<sup>1</sup>](#fn1) The pandemic triggered the \"Great Liquidity Crisis”, the largest volatility-adjusted re-pricing of markets in 30+ years, accompanied by the most aggressive market support operations conducted in central bank modern history. The impact of the COVID-19 crisis was felt worldwide taking a hefty toll on human lives and economic activity due to global lock-downs that were implemented to contain its spread. Fear and uncertainty translated into sharp and rapid declines of traditional financial assets and newly adopted asset classes globally, such as bitcoin.\n",
    "\n",
    "[<sup>2</sup>](#fn2) Nouriel Roubini, professor of economics at NYU’s Stern School of Business, entirely disagrees with the idea that something with no income, utility or relationship with economic fundamentals can be considered a store of value, or an asset at all. Please refer to Crypto: A New Asset Class - Goldman Sachs, (2021) - Interview with Nouriel Rubini, p.8 https://www.goldmansachs.com/insights/pages/crypto-a-new-asset-class-f/report.pdf\").\n",
    "\n",
    "[<sup>3</sup>](#fn3) Backpropagation is the primary means by which a neural network's weights are determined during training. Backpropagation works by calculating a weight change amount ($v_t$) for every weight($\\theta$, theata) in the neural network. This value is subtracted from every weight by the following equation: $\\theta_t = \\theta_{t-1} - v_t$\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aee5f98",
   "metadata": {},
   "source": [
    "### <font color= dodgerblue> BIBLIOGRAPHY</font> \n",
    "\n",
    "[1] Elmandjra Y. (White Paper) Bitcoin As Investment. Available at https://ark-invest.com/white-papers/bitcoin-part-two/, 2020.\n",
    "\n",
    "[2] Nakamoto S. (2008) “Bitcoin: A Peer-to Peer Electronic Cash System”, white paper, Bitcoin.org available at https://bitcoin.org/bitcoin.pdf\n",
    "\n",
    "[3] ICONIC FUNDS & CRYPTOLOGY ASSET GROUP: Analyzing the Primary Value Drivers of Leading Cryptocurrencies (2021) https://iconicholding.com/analyzing-the-primary-value-drivers-of-leading-cryptocurrencies/\n",
    "\n",
    "[4] Fran Casino, Thomas K. Dasaklis, Constantinos Patsakis,\n",
    "'A systematic literature review of blockchain-based applications: Current status, classification and open issues', Telematics and Informatics, Volume 36, 2019, Pages 55-81, ISSN 0736-5853,\n",
    "https://doi.org/10.1016/j.tele.2018.11.006.\n",
    "\n",
    "[5] IOSCO Research Report on Financial Technologies (Fintech), Report of the Board of IOSCO, February 2017 https://www.iosco.org/library/pubdocs/pdf/IOSCOPD554.pdf\n",
    "\n",
    "[6] “Mastering Blockchain by Lorne Lantz and Daniel Cawrey (O’Reilly). Copyright 2021 Lorne Lantz and Daniel Cawrey, 978-1-492-05470-2.”\n",
    "\n",
    "[7] Guseva, Yuliya, The SEC, Digital Assets and Game Theory (March 8, 2021). The Journal of Corporation Law (2021 Forthcoming), Rutgers Law School Research Paper No. Forthcoming, Available at SSRN: https://ssrn.com/abstract=3806116\n",
    "\n",
    "[8] Alexander C. and M. Dakos (2020) ‘A Critical Investigation of Cryptocurrency Data and Analysis’ Quantitative Finance. 20:2, 173-188\n",
    "\n",
    "[9] On-Chain Data: A New Framework to Evaluate Bitcoin by Yassine Elmandjra, Analyst (January 11, 2021)https://ark-invest.com/articles/analyst-research/on-chain-data-bitcoin/\n",
    "\n",
    "[10] Stoner, A., & Prof.  Dr.  Sandner, P. (2020).  Using On-Chain and Market Metrics to Analyze the Value of Crypto Assets.  FSBC Working Paper, pp.  1-22.  available at https://philippsandner.medium.com/using-on-chain-and-market-metrics-to-analyze-the-value-of-crypto-assets-80141ad714d6\n",
    "\n",
    "[11] Introducing-on-chain-bitcoin-analysis (Mar 27, 2021)\n",
    "https://bitcoinmagazine.com/markets/introducing-on-chain-bitcoin-analysis\n",
    "\n",
    "[12] The Bitcoin On-Chain Indicators Primer\n",
    "https://coinmetrics.io/on-chain-indicators/\n",
    "\n",
    "[13] A paper by Bhambhwani et al (“The fundamental drivers of cryptocurrency prices,” 2019) suggests that computing power and network factors can explain return variations across a broad set of cryptocurrencies.\n",
    "\n",
    "[14] Hilpisch Y. (2020) Artificial Intelligence in Finance – A Python-Based Guide, O’Reilly Media, Inc.\n",
    "\n",
    "[15] Y. Hilpisch. (2020) Python for Algorithmic Trading. O’Reilly Media, Inc. \n",
    "\n",
    "[16] T. Guida. \"Big Data and Machine Learning in Quantitative Investment\". John Wiley & Sons, Ltd. ISBN 9781119522195. (2019)\n",
    "\n",
    "[17] M. Lopez de Prado. \"Advances in Financial Machine Learning\" (2018) Published by John Wiley & Sons, Inc., Hoboken, New Jersey. ISBN 978-1-119-48208-6\n",
    "\n",
    "[18] Wharton  Blockchain  and  Digital  Asset  Project,  in  collaboration  with  the  World  EconomicForum, DeFi Beyond the Hype The Emerging World of Decentralized Finance, 2021.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
